---
title: "Reconstrucción de Egeland et al., 2018: 'Hominin skeletal part abundances...'"
author: 'Antonio Canepa-Oneto'
date: "Last compiled on `r format(Sys.time(), '%d %B, %Y')`"
output:
  github_document:
    keep_html: true
---

## Introducción
Se hace una mini-revisión de lo reportado en *Hominin skeletal part abundances and claims of deliberate disposal of corpses in the Middle Pleistocene*[https://doi.org/10.1073/pnas.1718678115](https://doi.org/10.1073/pnas.1718678115)

Los procesos funerarios humanos tiene una antiguedad determinada (desde cuándo somos conscientes de nuestra muerte) que está bajo escrutinio y constante debate. Gracias a un estudio de diversos yacimientos se intenta esclarecer ese posible supuesto de primer origen de enterramientos funerarios para los yacimientos de Atapuerca (**SH**) y Sudáfrica (**DC**).

Cuando se encuentra y analiza un yacimiento de homínidos (u homininos para ser más precisos) es posible que no todos los huesos estén en perfecto estado y más notable aún es posible que no todos los huesos estén presentes. La ausencia de determinados huesos puede deberse a procesos aleatorios (deterioro, rompimiento, etc), semi-aleatorios (consumo de carroña de partes específicas) o altamente selectivos (ritos funerarios).

Afortunamente existe una cantidad interesante de yacimientos con restos humanos y de primates ("cercanos") que pueden dar pistas de si los yacimientos **SH** y **DC** pueden (o no) considerarse procesos rituales (muy específicos) o simplemente procesos aleatorios y/o semi-aleatorios.

### Objetivos
Los objetivos del artículo son tratar de comparar los yacimientos de **SH** y **DC** con yacimientos conocidos para determinar si la estructura (como composición unitaria, no como forma) de huesos disponibles es ás característico de un rito funerario o de un proceso de pérdida aleatorio (descomposición) o semi-aleatorio (carroña).

#### Diseño de Análisis
La idea general es que ellos comparan los huesos encontrados ("*Hominin skeletal part representation* - __HSPR__") con otros 14 yacimientos entre los cuales existen algunos de humanos en estado "completo" en el que no le falta ninguna pieza.

Para eso ellos:
1.-   Usando un Random Forest (RF) determinan cuáles son las piezas de huesos con más variabilidad (Gini idex y MDA), para utilizarlas luego en la creación/clasificación de grupos.
2.-   Usando un primer k-means logran crear dos grupos de "HSPR", en los que los huesos humanos "completos" y otros yacimientos en buen estado quedan juntos en un cluster y el segundo cluster atribuyen a carroña, canibalismo, etc. mostrando un proceso de acumulación natural (__no ritual__).
3.-   Repiten el k-means con más grupos y encuentran un gradiente de conservación de 4 grupos desde los más completos hasta los netamente depredados/erosionados.
4.-   Usando herramientas supervisadas intentan clasificar los yacimientos (todos) con especial interés en **SH** y **DC** en alguno de los grupos ya reconocidos por los k-means anteriores.
5.-   Usando herramientas no-supervisadas intentan agrupar los yacimientos (todos) con especial interés en **SH** y **DC** para ver si coinciden con las características/grupos encontradas en los k-means anteriores.

El conjunto 
The dataset was compiled by Antonio Canepa-Oneto, following the Supporting Information found [here](https://www.pnas.org/doi/suppl/10.1073/pnas.1718678115/suppl_file/pnas.1718678115.sd01.xlsx).

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(gt)
library(tidyverse)
```

The dataset (only the first fifteen rows) looks like:


```{r, message=FALSE, warning=FALSE}
Summary_Dataset <- read_csv("INPUT/DATA/Summary_Dataset.csv")

Summary_Dataset %>% 
  slice_head(n = 15) %>% 
  gt()
```

## Statistical Treatment of Primate Skeletal Part Data
All analyses described below are run within the R statistical environment


The algorithms implemented, the packaged used for and the URL for those packages are listed in the following table:


```{r echo=FALSE}
packages <- tibble(
  Algorithm = c("Neural Network",
                "Neural Network",
                "SVM", 
                "SVM", 
                "Decision tree with C5.0", 
                "Decision tree with C5.0",
                "KNN",
                "KNN",
                "Random Forest",
                "Random Forest"
                ),
  Package_used = c("neuralnet", 
                    "caret", 
                    "e1071", 
                    "caret", 
                    "C50",
                    "caret",
                    "class",
                    "knn/fknn",
                    "randomForest",
                    "caret"
                    ),
  Packages_Link = c("https://cran.r-project.org/web/packages/neuralnet/",
                    "https://cran.r-project.org/web/packages/caret/index.html",
                    "https://cran.r-project.org/web/packages/e1071/index.html",
                    "https://cran.r-project.org/web/packages/caret/index.html",
                    "https://cran.r-project.org/web/packages/C50/index.html",
                    "https://cran.r-project.org/web/packages/caret/index.html",
                    "https://cran.r-project.org/web/packages/class/index.html",
                    "https://cran.r-project.org/web/packages/FastKNN/index.html",
                    "https://cran.r-project.org/web/packages/randomForest/index.html",
                    "https://cran.r-project.org/web/packages/caret/index.html"
                    )
)

#packages
```



```{r, echo=FALSE}
# using markdown
packages %>%
  mutate(
    link = glue::glue("[website]({Packages_Link})"),
    link = map(Packages_Link, gt::md)) %>%
  select(!Packages_Link) %>% 
  gt() %>% 
  tab_header(
    title = md("List of algorithms used in Egeland et al., 2018"),
    subtitle = "R Packages and their URL are given"
  ) %>% 
  cols_label(
    Algorithm = "Algorithm",
    Package_used = "Package used",
    link = "Package URL") %>%  
  tab_footnote(data = .,
               footnote = "No 'knn' package was found. Similar algorithm in FastKNN - fknn",
               # locations = cells_body(columns = Package_used, rows = everything()
               locations = cells_body(columns = Package_used, rows = Package_used == 'knn/fknn')
  )
```



## Exploratory analysis. 
Some key points from the paper itself are highlighted here.

The goal of exploratory analysis is twofold: (i) to identify the optimum number of groups represented by the hominin assemblages and (ii) to determine the membership of each identified group. Many grouping algorithms tend to perform poorly when, as is the case here, the number of variables (skeletal elements = 23) substantially exceeds sample size (hominin assemblages = 16). To address this discrepancy, we used a RF analysis on all 16 assemblages, including the SH and DC, to identify a subset of skeletal elements that is smaller than the sample size and explains the greatest amount of variance (120). To identify the optimum number of groups represented by all 16 assemblages, those skeletal elements with a MDA value > 5 after the generation of 500 trees are entered in the “NbClust” R library, which runs and combines 30 different clustering algorithms. A k-means analysis then classifies each of the comparative assemblages into one of the groups recognized by the NbClust functions. The strength of group assignment is assessed with the “clusplot” graphic function, which provides 95% confidence ellipses and silhouette plots, which estimate the s(i) value of each comparative assemblage. A comparison of within- and between-group distances results in s(i) values that range from 1 (strong classification within a group) to 0 (parsimonious but weak classification within a group). This preliminary classification establishes a framework for the application of a variety of machine-learning methods that can identify the comparative assemblages that best match the hominin concentrations from the SH and DC.

Before model construction, all skeletal part data undergo center and scale transformation

To choose the best model for analysis, we use Monte-Carlo leave-group-out cross-validation resampling. This creates multiple training set/testing set splits and is more robust with small samples than bootstrapping, bagging, and k-fold cross-validation methods

The models produced by each machine learning method after 30 iterations are evaluated with Cohen’s κ.

Finally, we perform an unsupervised CA with PCA loading scores.


